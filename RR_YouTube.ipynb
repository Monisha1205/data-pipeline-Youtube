{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fa59d4-bcc5-4008-b173-ec0be6ce5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Using cached SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from SpeechRecognition) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
      "Using cached SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.10.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install instaloader\n",
    "#!pip install moviepy\n",
    "#!pip install  SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3f010a-c987-49a2-8faa-8bef29945632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import instaloader\n",
    "from moviepy.editor import VideoFileClip\n",
    "import speech_recognition as sr\n",
    "#import SpeechRecognition as sr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc2b6eb-fee1-4d54-b724-4b71e61bf9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_video(url, output_path='youtube_video.mp4'):\n",
    "    yt = YouTube(url)\n",
    "    stream = yt.streams.filter(file_extension='mp4').first()\n",
    "    stream.download(filename=output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf91195a-915e-419a-97b1-b62931417cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path=download_youtube_video(\"https://youtube.com/shorts/SGQ0r_0jP_Q?si=cJIHjiwPZ7kIWUoV\", output_path='youtube_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334e6242-2e01-4c88-85a4-9887a49d458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_from_video(video_path, audio_path='audio.wav'):\n",
    "    with VideoFileClip(video_path) as video:\n",
    "        video.audio.write_audiofile(audio_path)\n",
    "    return audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f28aa8b-09f9-4371-9e90-8c7f76a24712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "audio_path=extract_audio_from_video(video_path, audio_path='audio.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3637ad15-40f6-4c53-819d-0dc92aff15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split audio into smaller segments\n",
    "def split_audio(audio_path, segment_length=60):\n",
    "    from pydub import AudioSegment\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    segments = [audio[i:i + segment_length * 1000] for i in range(0, len(audio), segment_length * 1000)]\n",
    "    segment_paths = []\n",
    "    for idx, segment in enumerate(segments):\n",
    "        segment_path = f\"{audio_path[:-4]}_part{idx + 1}.wav\"\n",
    "        segment.export(segment_path, format=\"wav\")\n",
    "        segment_paths.append(segment_path)\n",
    "    return segment_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1eaea58-ebd5-4fcc-b7ac-636139063b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydubNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "#pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a6c504a-2189-4c69-99a4-c0b59e8c23f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pathlist=split_audio(audio_path, segment_length=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c652442e-002b-4b92-81f9-2a495ee0b2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'audio_part1.wav'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_pathlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413665c-fc3c-4b15-b2b3-9d9b3c3692b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c5f1f-567f-4de9-a92b-786bfa7dd03b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becdaade-6c1d-4fa1-93dd-aef2d3632e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee3f750-4bb3-472c-bb86-37ad84ef47b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: Could not process the audio using Sphinx; missing PocketSphinx module: ensure that PocketSphinx is set up correctly.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def transcribe_audio_with_sphinx(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    try:\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            audio_data = recognizer.record(source)\n",
    "            \n",
    "            # Recognize speech using Sphinx\n",
    "            text = recognizer.recognize_sphinx(audio_data)\n",
    "            \n",
    "    except sr.UnknownValueError:\n",
    "        text = \"Sphinx could not understand audio\"\n",
    "    except sr.RequestError as e:\n",
    "        text = f\"Could not process the audio using Sphinx; {e}\"\n",
    "    except Exception as e:\n",
    "        text = f\"An error occurred: {e}\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "#audio_path = \"path/to/your/audiofile.wav\"\n",
    "transcription = transcribe_audio_with_sphinx(audio_path)\n",
    "print(f\"Transcription: {transcription}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e64fb4af-045c-489f-9c19-49dcad8fe54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.30.3-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from openai) (4.2.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "     ---------------------------------------- 0.0/107.3 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 20.5/107.3 kB 217.9 kB/s eta 0:00:01\n",
      "     -------------- ---------------------- 41.0/107.3 kB 393.8 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 102.4/107.3 kB 737.3 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 102.4/107.3 kB 737.3 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 102.4/107.3 kB 737.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ 107.3/107.3 kB 413.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.18.2-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\aidl\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
      "   ---------------------------------------- 0.0/320.6 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 92.2/320.6 kB 2.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 143.4/320.6 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 235.5/320.6 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  317.4/320.6 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  317.4/320.6 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 320.6/320.6 kB 1.2 MB/s eta 0:00:00\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/75.6 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 71.7/75.6 kB 991.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 71.7/75.6 kB 991.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 71.7/75.6 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 75.6/75.6 kB 321.9 kB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 71.7/77.9 kB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 71.7/77.9 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 77.9/77.9 kB 541.5 kB/s eta 0:00:00\n",
      "Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.3 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 61.4/409.3 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 163.8/409.3 kB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 245.8/409.3 kB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 378.9/409.3 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  399.4/409.3 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  399.4/409.3 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 409.3/409.3 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.18.2-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.9 MB 3.3 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.2/1.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.3/1.9 MB 1.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.4/1.9 MB 1.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/1.9 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/1.9 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.6/1.9 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/1.9 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.7/1.9 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.7/1.9 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.7/1.9 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.9 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.9/1.9 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.9/1.9 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.9/1.9 MB 988.5 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/1.9 MB 988.5 kB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 982.8 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.9 MB 958.5 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.9 MB 945.4 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 921.2 kB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 939.5 kB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 920.4 kB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 920.4 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 883.8 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 871.3 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 864.1 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/1.9 MB 862.0 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.4/1.9 MB 882.9 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 884.5 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.5/1.9 MB 898.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.9 MB 947.2 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 962.5 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 968.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.8/1.9 MB 972.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 975.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 982.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 982.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 982.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 917.4 kB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 51.2/58.3 kB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 51.2/58.3 kB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 58.3/58.3 kB 384.2 kB/s eta 0:00:00\n",
      "Installing collected packages: pydantic-core, h11, distro, annotated-types, pydantic, httpcore, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.3 pydantic-2.7.1 pydantic-core-2.18.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1960189-453c-48c4-bf31-025136eb135c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "#response = messages.data[0].content[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082dba75-5679-4731-8e6c-f6fe4d07507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='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')\n",
    "\n",
    "\n",
    "def get_completion_from_messages(messages,\n",
    "                                 model=\"gpt-3.5-turbo\",\n",
    "                                 temperature=0,\n",
    "                                 max_tokens=500):\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=messages,\n",
    "      temperature=temperature,\n",
    "      max_tokens=max_tokens,\n",
    "  )\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c308cda0-d567-4b9f-981d-abc017d098b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \"####\"\n",
    "system_message = f\"\"\"\n",
    "You will be provided with youtube and instagram  shorts and reels text content,\n",
    "I want you to classify the context into \"Hook\",\"Bulid up\", \"Body\",\"call to action\". \n",
    "follow these rules before you classify, I want every classification to be present either in stright way or indirect way\" with detailed explannation.\n",
    "\n",
    "return the output in the .json format with detailed explannation. only in .json format should have only \"Hook\",\"Bulid up\", \"Body\",\"call to action\".\n",
    "for example:\n",
    "\n",
    "    \"Hook\":\"You need to steal from six figures to seven years\".The opening sentence of the text serves as a hook by presenting a \n",
    "  provocative statement that grabs the audience's attention and entices them to continue reading or listening to the content.\"\n",
    "    \"Build up\": \"The first husband is a virtual assistant and actually few years ago I placed over two thousand for frozen zoos for businesses online\".\n",
    "  The text provides background information and sets the stage for introducing the concept of hiring a virtual assistant and the potential benefits it\n",
    "  can bring to a business,creating a build-up towards the main points being discussed.\"\n",
    "    \"Body\": \"You're doing cold calls every day, you're setting up an account for your clients, you're doing every single day that Asia's current \n",
    "    easier to measure work a message for pattern that you cannot manage\",.\n",
    "    This section elaborates on the tasks and responsibilities involved in running a business, such as making cold calls,\n",
    "    client account management, and the challenges of managing workload efficiently. It forms the main body of the content by\n",
    "    providing detailed information and insights.\"\n",
    "    \"Call to action\": \"If you're not free videos you definitely need to build trust with your prospects by leaving the call to begin work and so editing\n",
    "    videos of primitive hoping to do and it's fine to me why work with him so my clients have millions of stars on youtube they're still getting around\n",
    "    it and sullivan say they'd like doing it which is fine\",The text concludes with a call to action by emphasizing the importance of utilizing videos to build trust with prospects and \n",
    "    engage with the audience effectively. It encourages the audience to take action by leveraging video content to enhance their business strategies and \n",
    "    connect with potential clients.\"\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "user_message = transcription\n",
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content': system_message},    \n",
    "{'role':'user', \n",
    " 'content': f\"{delimiter}{user_message}{delimiter}\"},  \n",
    "] \n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c2cae-d2a3-4683-b5a4-0bb97b2c503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5e706-bcba-4f98-94b6-acfeea2c9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Raw input string\n",
    "raw_input = response\n",
    "\n",
    "# Split the raw input into individual JSON objects\n",
    "raw_json_objects = raw_input.strip().split(\"\\n\\n\")\n",
    "\n",
    "# Parse each JSON object and collect them into a list\n",
    "data_list = []\n",
    "for raw_json in raw_json_objects:\n",
    "    data_list.append(json.loads(raw_json))\n",
    "\n",
    "# Organize data into a dictionary format\n",
    "data_dict = {}\n",
    "for item in data_list:\n",
    "    for key, value in item.items():\n",
    "        if key != \"Explanation\":\n",
    "            section = key\n",
    "            content = value\n",
    "            explanation = item[\"Explanation\"]\n",
    "            combined_content = f\"{content} {explanation}\"\n",
    "            data_dict[section] = combined_content\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame([data_dict])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43ed9d-1d12-4fb9-b594-724131fd73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a61aa-f3b2-4276-b625-6e6f1280d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Reference\"]=\"https://www.instagram.com/reel/C6hF7ybyqIJ/?igsh=MXdjeXpjNTd4bzU0cQ==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea89991-c7c2-445b-a5ff-42968719110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b18f4-c2e1-432b-ac66-c51b5901f71a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
